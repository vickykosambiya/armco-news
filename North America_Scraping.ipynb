{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de756b02-897f-4143-8e5e-72962c357638",
   "metadata": {},
   "source": [
    "### Bloomberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7930855-26d9-4023-b379-220ecd2c4426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title not found.\n",
      "\n",
      "Date not found.\n",
      "\n",
      "Content:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html  # For parsing HTML\n",
    "\n",
    "# Step 1: Send a GET request to the URL\n",
    "url = 'https://www.bloomberg.com/news/articles/2024-12-11/xi-readies-bargaining-chips-for-us-trade-war-after-biden-curbs?srnd=homepage-asia'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "tree = html.fromstring(r.content)\n",
    "\n",
    "# Step 3: Find the element with class \"newsdetail_title\"\n",
    "title_element = tree.xpath('//h1[@class=\"media-ui-HedAndDek_headline-D19MOidHYLI-\"]')\n",
    "if title_element:\n",
    "    title_text = title_element[0].text_content().strip()\n",
    "    print(\"Title:\")\n",
    "    print(title_text)\n",
    "else:\n",
    "    print(\"Title not found.\")\n",
    "\n",
    "# Step 4: Find the date element with class \"p-date\"\n",
    "date_element = tree.xpath('//time')\n",
    "if date_element:\n",
    "    date_text = date_element[0].text_content().strip()\n",
    "    print(\"\\nDate:\")\n",
    "    print(date_text)\n",
    "else:\n",
    "    print(\"\\nDate not found.\")\n",
    "\n",
    "# Step 5: Find all <p> elements inside the div with class \"storytext\"\n",
    "paragraph_divs = tree.xpath('//div[@class=\"body-content\"]/p')\n",
    "\n",
    "# Step 6: Extract and print text content from each <p> element\n",
    "print(\"\\nContent:\")\n",
    "for paragraph in paragraph_divs:\n",
    "    cleaned_text = paragraph.text_content().strip()\n",
    "    print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123290a9-f200-49a5-9ea6-4df64537e907",
   "metadata": {},
   "source": [
    "### CNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ac335c-350a-467a-81f5-46b4b1e05d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Alphabet shares jump 6% after Google touts 'breakthrough' quantum chip\n",
      "\n",
      "Date:\n",
      "Published Tue, Dec 10 20242:22 PM EST\n",
      "\n",
      "Content:\n",
      "Alphabet shares rose 6% on Tuesday, the day after the company hailed its latest quantum computing chip as a \"breakthrough.\"\n",
      "The Google parent company on MondayÂ revealed \"Willow,\"Â a quantum computing chip that the company said performed significantly better on a quantum computing benchmark than its predecessor did in 2019. Willow, like similar quantum chips, uses uncertain \"qubits\" to represent numbers instead of transistors, which are used on traditional semiconductors. Google said its technology can reduce expected errors faster than they appear as quantum chips get bigger, which has been a bottleneck in the development of better quantum computers.\n",
      "Willow is the second milestone in a six-step strategy to develop quantum computers that can perform useful applications, Google said. The chip has about 100 qubits, but Google is planning to eventually build a system with 1 million qubits.\n",
      "\"Willow brings us closer to running practical, commercially-relevant algorithms that can't be replicated on conventional computers,\" Google wrote in a blog post, adding that the experiment is evidence that suggests that reality is comprised of parallel universes.\n",
      "\"We see Willow as an important step in our journey to build a useful quantum computer with practical applications in areas like drug discovery, fusion energy, battery design + more,\" Google CEO Sundar Pichai said on X.\n",
      "When quantum computing matures, it is expected to be useful for large-scale simulations and code breaking, but that may not be possible for years or decades. Google isn't the only tech giant working on quantum computing. Nvidia, Microsoft and IBM are also working on the technology, in addition to researchers at startups and universities.\n",
      "Google's announcement was praised on social media by several technology business figures, including Tesla CEO Elon Musk and OpenAI CEO Sam Altman.\n",
      "\"We should do a quantum cluster in space with Starship one day,\" Pichai replied to Musk.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html  # For parsing HTML\n",
    "\n",
    "# Step 1: Send a GET request to the URL\n",
    "url = 'https://www.cnbc.com/2024/12/10/alphabet-shares-jump-5percent-after-google-touts-breakthrough-quantum-chip-.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "tree = html.fromstring(r.content)\n",
    "\n",
    "# Step 3: Find the element with class \"newsdetail_title\"\n",
    "title_element = tree.xpath('//h1[@class=\"ArticleHeader-headline\"]')\n",
    "if title_element:\n",
    "    title_text = title_element[0].text_content().strip()\n",
    "    print(\"Title:\")\n",
    "    print(title_text)\n",
    "else:\n",
    "    print(\"Title not found.\")\n",
    "\n",
    "# Step 4: Find the date element with class \"p-date\"\n",
    "date_element = tree.xpath('//time[@data-testid=\"published-timestamp\"]')\n",
    "if date_element:\n",
    "    date_text = date_element[0].text_content().strip()\n",
    "    print(\"\\nDate:\")\n",
    "    print(date_text)\n",
    "else:\n",
    "    print(\"\\nDate not found.\")\n",
    "\n",
    "# Step 5: Find all <p> elements inside the div with class \"storytext\"\n",
    "paragraph_divs = tree.xpath('//div[@class=\"group\"]/p')\n",
    "\n",
    "# Step 6: Extract and print text content from each <p> element\n",
    "print(\"\\nContent:\")\n",
    "for paragraph in paragraph_divs:\n",
    "    cleaned_text = paragraph.text_content().strip()\n",
    "    print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f553d3e-68a7-4507-ade1-357d8ce14968",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03af61f-9956-4cf0-8d0b-033771be5846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "âNo winnersâ: Chinaâs Xi warns US against a trade war\n",
      "\n",
      "Date:\n",
      "Published\n",
      "        9:42 AM EST, Tue December 10, 2024\n",
      "\n",
      "Content:\n",
      "Editorâs Note: Sign up for CNNâs Meanwhile in China newsletter which explores what you need to know about the countryâs rise and how it impacts the world.\n",
      "Chinese leader Xi Jinping has warned the United States against restarting a trade war, saying there would be âno winnersâ even as he vowed to defend the countryâs economic interests.\n",
      "Xi made the remarks on Tuesday during a meeting with the heads of several global financial institutions, including the World Bank and International Monetary Fund, a day after Chinese regulators announced an antitrust investigation into American chip maker Nvidia.\n",
      "The probe is widely seen as a major escalation in a growing battle for AI dominance, which both Washington and Beijing believe is crucial to safeguarding national security, even before Donald Trump returns to the White House.\n",
      "âTariff wars, trade wars, and technology wars go against the historical trend and economic laws, and there will be no winners,â Xi said according to state broadcaster CCTV.\n",
      "âBuilding âsmall courtyards with high wallsâ and âdecoupling and breaking chainsâ will hurt others and not benefit oneself. China has always believed that only when China is good can the world be good. Only when the world is good can China be better,â he added.\n",
      "US National Security Advisor Jake Sullivan has used the âsmall yard and high fenceâ phrase to describe a strategy of allowing most trade with China to progress normally while placing restrictions on some goods, particularly high-tech products like semiconductors, deemed to have military applications.\n",
      "Last week, the Biden administration announced a third round of export curbs in as many years restricting Beijingâs access to two dozen types of semiconductor-making equipment and advanced memory chips, as well as placing controls on more than 100 Chinese companies.\n",
      "Trump said last month China will face higher tariffs on its goods, by 10% above any existing tariffs, until it prevents the flow of illegal drugs into the US.\n",
      "In an interview that aired Sunday on NBC, the incoming president said he and Xi had been âcommunicating with each otherâ a few days previously. When asked about the discussion at a regular briefing on Monday, a spokesperson for Chinaâs Foreign Ministry did not directly confirm or deny it.\n",
      "China is relying on exports, particularly to major trading partners like the United States, as a key engine of growth as domestic demand slumps because of a number of economic problems. On Tuesday, official data showed that exports fell sharply, and imports unexpectedly shrank last month.\n",
      "Exports grew by just 6.7% in November. It was noticeably weaker than the 8.5% forecast by a group of economists polled by Reuters and much lower than an increase of 12.7% in October.\n",
      "âWe doubt this marks an end to Chinaâs recent export boom,â Zichun Huang of Capital Economics wrote in a research note. âAlthough US tariffs could reduce export volumes by around 3%, they may not be felt until the middle of next year. In the meantime, the threat of tariffs may even spur exports as US firms ramp up orders in anticipation.â\n",
      "The need to prepare for âexternal shocksâ was cited in Mondayâs readout of a meeting by the Communist Partyâs powerful Politburo, which made headlines by announcing it would adopt a âmoderately looseâ monetary policy next year. Economists said the wording meant monetary policy, which involves influencing interest rates, was being relaxed for the first time since 2010.\n",
      "âIt is likely that China would continue to improve trade relations through lower export tax rebate and clearer rules including government procurement,â Citi economists wrote on Monday.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html  # For parsing HTML\n",
    "\n",
    "# Step 1: Send a GET request to the URL\n",
    "url = 'https://edition.cnn.com/2024/12/10/business/china-us-trade-war-xi-warning-hnk-intl/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "tree = html.fromstring(r.content)\n",
    "\n",
    "# Step 3: Find the element with class \"newsdetail_title\"\n",
    "title_element = tree.xpath('//h1[@class=\"headline__text inline-placeholder vossi-headline-text\" and @data-editable=\"headlineText\"]')\n",
    "if title_element:\n",
    "    title_text = title_element[0].text_content().strip()\n",
    "    print(\"Title:\")\n",
    "    print(title_text)\n",
    "else:\n",
    "    print(\"Title not found.\")\n",
    "\n",
    "# Step 4: Find the date element with class \"p-date\"\n",
    "date_element = tree.xpath('//div[@class=\"timestamp vossi-timestamp\" and @data-uri=\"cms.cnn.com/_components/timestamp/instances/cm4ibbkza00ee25pabgi31y0n@published\"]')\n",
    "if date_element:\n",
    "    date_text = date_element[0].text_content().strip()\n",
    "    print(\"\\nDate:\")\n",
    "    print(date_text)\n",
    "else:\n",
    "    print(\"\\nDate not found.\")\n",
    "\n",
    "# Step 5: Find all <p> elements inside the div with class \"storytext\"\n",
    "paragraph_divs = tree.xpath('//div[@class=\"article__content\" and @data-editable=\"content\" and @itemprop=\"articleBody\" and @data-reorderable=\"content\"]/p')\n",
    "\n",
    "# Step 6: Extract and print text content from each <p> element\n",
    "print(\"\\nContent:\")\n",
    "for paragraph in paragraph_divs:\n",
    "    cleaned_text = paragraph.text_content().strip()\n",
    "    print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a2a7b-ae8c-44c2-a528-68ace524ed93",
   "metadata": {},
   "source": [
    "### Reuters Breakingviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78033fec-1048-4c21-8c98-15b415523791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title not found.\n",
      "\n",
      "Date not found.\n",
      "\n",
      "Content:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html  # For parsing HTML\n",
    "\n",
    "# Step 1: Send a GET request to the URL\n",
    "url = 'https://www.breakingviews.com/considered-view/hershey-would-be-a-bitter-confection-to-swallow/'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "tree = html.fromstring(r.content)\n",
    "\n",
    "# Step 3: Find the element with class \"newsdetail_title\"\n",
    "title_element = tree.xpath('//h1')\n",
    "if title_element:\n",
    "    title_text = title_element[0].text_content().strip()\n",
    "    print(\"Title:\")\n",
    "    print(title_text)\n",
    "else:\n",
    "    print(\"Title not found.\")\n",
    "\n",
    "# Step 4: Find the date element with class \"p-date\"\n",
    "date_element = tree.xpath('//div[contains(@class, \"c-haNASs\")]')\n",
    "if date_element:\n",
    "    date_text = date_element[0].text_content().strip()\n",
    "    print(\"\\nDate:\")\n",
    "    print(date_text)\n",
    "else:\n",
    "    print(\"\\nDate not found.\")\n",
    "\n",
    "# Step 5: Find all <p> elements inside the div with class \"storytext\"\n",
    "paragraph_divs = tree.xpath('//p')\n",
    "\n",
    "# Step 6: Extract and print text content from each <p> element\n",
    "print(\"\\nContent:\")\n",
    "for paragraph in paragraph_divs:\n",
    "    cleaned_text = paragraph.text_content().strip()\n",
    "    print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cac44-fdb3-4e41-b3c8-882a69423099",
   "metadata": {},
   "source": [
    "### WSJ - Wall Street Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6c4457-a14a-42c8-9367-3ab5cf32a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title not found.\n",
      "\n",
      "Date not found.\n",
      "\n",
      "Content:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html  # For parsing HTML\n",
    "\n",
    "# Step 1: Send a GET request to the URL\n",
    "url = 'https://www.wsj.com/us-news/luigi-mangione-united-healthcare-shooting-suspect-police-manhunt-4f5aeea8?mod=hp_lead_pos8'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "tree = html.fromstring(r.content)\n",
    "\n",
    "# Step 3: Find the element with class \"newsdetail_title\"\n",
    "title_element = tree.xpath('//h1[@class=\"css-1lvqw7f-StyledHeadline e1ipbpvp0\"]')\n",
    "if title_element:\n",
    "    title_text = title_element[0].text_content().strip()\n",
    "    print(\"Title:\")\n",
    "    print(title_text)\n",
    "else:\n",
    "    print(\"Title not found.\")\n",
    "\n",
    "# Step 4: Find the date element with class \"p-date\"\n",
    "date_element = tree.xpath('//time[@datetime=\"2024-12-10T23:59:00Z\" and @class=\"css-1u347bo-Timestamp-Timestamp emlnvus2\"]')\n",
    "if date_element:\n",
    "    date_text = date_element[0].text_content().strip()\n",
    "    print(\"\\nDate:\")\n",
    "    print(date_text)\n",
    "else:\n",
    "    print(\"\\nDate not found.\")\n",
    "\n",
    "# Step 5: Find all <p> elements inside the div with class \"storytext\"\n",
    "paragraph_divs = tree.xpath('//section[@class=\"ef4qpkp0 css-f9cbye-Container etunnkc21\"]/p')\n",
    "\n",
    "# Step 6: Extract and print text content from each <p> element\n",
    "print(\"\\nContent:\")\n",
    "for paragraph in paragraph_divs:\n",
    "    cleaned_text = paragraph.text_content().strip()\n",
    "    print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27c44e-a5f4-4583-b32e-5931b40eb836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
